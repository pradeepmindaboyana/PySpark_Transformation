{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58546fda",
   "metadata": {},
   "source": [
    "\n",
    "Basic Query\n",
    "1.Write a PySpark code to display the names and salaries of employees in the \"IT\" department.\n",
    "\n",
    "Filtering Data\n",
    "2.Write a PySpark code to filter out employees who joined after \"2021-01-01\".\n",
    "\n",
    "Aggregation\n",
    "3.Write a PySpark code to calculate the average salary of employees in each department.\n",
    "\n",
    "Sorting\n",
    "4.Write a PySpark code to sort the DataFrame by salary in descending order.\n",
    "\n",
    "Column Operations\n",
    "5.Write a PySpark code to add a new column named salary_increase which is 10% of the current salary.\n",
    "\n",
    "Date Manipulation\n",
    "6.Write a PySpark code to extract the year from the join_date column and create a new column join_year.\n",
    "\n",
    "Group By and Aggregation\n",
    "7.Write a PySpark code to group employees by department and count the number of employees in each department.\n",
    "\n",
    "String Operations\n",
    "8.Write a PySpark code to create a new column full_name that concatenates name with the department, separated by a hyphen.\n",
    "\n",
    "Duplicate Rows\n",
    "9.Write a PySpark code to drop duplicate rows based on the emp_id column.\n",
    "\n",
    "Joining DataFrames\n",
    "10.Write a PySpark code to join this DataFrame with another DataFrame df2 on the emp_id column.\n",
    "\n",
    "Handling Null Values\n",
    "11.Write a PySpark code to fill null values in the salary column with the average salary of the department.\n",
    "\n",
    "Filtering with Conditions\n",
    "12.Write a PySpark code to filter employees who either have a salary greater than 65000 or have joined in 2022.\n",
    "\n",
    "Window Functions\n",
    "13.Write a PySpark code to add a column rank which ranks employees within each department based on their salary in descending order.\n",
    "\n",
    "Pivot Tables\n",
    "14.Write a PySpark code to pivot the DataFrame to show the sum of salaries for each department by year of join.\n",
    "\n",
    "Complex Aggregation\n",
    "15.Write a PySpark code to calculate the maximum salary for each department and the percentage difference from the average salary in that department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92faeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "data = [\n",
    "    (1, \"John\", \"IT\", 60000, \"2022-01-15\"),\n",
    "    (2, \"Jane\", \"HR\", 55000, \"2021-03-22\"),\n",
    "    (3, \"Mike\", \"IT\", 70000, \"2022-06-18\"),\n",
    "    (4, \"Sara\", \"Finance\", 75000, \"2020-11-30\"),\n",
    "    (5, \"Amy\", \"HR\", 58000, \"2021-05-10\"),\n",
    "    (6, \"Tom\", \"IT\", 65000, \"2023-02-25\"),\n",
    "    (7, \"Lisa\", \"Finance\", 72000, \"2022-07-14\"),\n",
    "    (8, \"Mark\", \"IT\", 68000, \"2021-12-01\"),\n",
    "    (9, \"Eva\", \"HR\", 59000, \"2020-09-10\"),\n",
    "    (10, \"John\", \"IT\", 60000, \"2022-01-15\")]\n",
    "df = spark.createDataFrame(data, [\"emp_id\", \"name\", \"department\", \"salary\", \"join_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ef12b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- join_date: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "df.createOrReplaceTempView(\"DF\")\n",
    "df.printSchema()\n",
    "df.orderBy('join_date',ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da413307",
   "metadata": {},
   "source": [
    "# Basic Query\n",
    "1.Write a PySpark code to display the names and salaries of employees in the \"IT\" department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1ddc6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>name</th><th>salary</th></tr>\n",
       "<tr><td>IT</td><td>John</td><td>60000</td></tr>\n",
       "<tr><td>IT</td><td>Mike</td><td>70000</td></tr>\n",
       "<tr><td>IT</td><td>Tom</td><td>65000</td></tr>\n",
       "<tr><td>IT</td><td>Mark</td><td>68000</td></tr>\n",
       "<tr><td>IT</td><td>John</td><td>60000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+----+------+\n",
       "|department|name|salary|\n",
       "+----------+----+------+\n",
       "|        IT|John| 60000|\n",
       "|        IT|Mike| 70000|\n",
       "|        IT| Tom| 65000|\n",
       "|        IT|Mark| 68000|\n",
       "|        IT|John| 60000|\n",
       "+----------+----+------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.department=='IT').select(\"department\",\"name\",\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "282384db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>name</th><th>salary</th></tr>\n",
       "<tr><td>IT</td><td>John</td><td>60000</td></tr>\n",
       "<tr><td>IT</td><td>Mike</td><td>70000</td></tr>\n",
       "<tr><td>IT</td><td>Tom</td><td>65000</td></tr>\n",
       "<tr><td>IT</td><td>Mark</td><td>68000</td></tr>\n",
       "<tr><td>IT</td><td>John</td><td>60000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+----+------+\n",
       "|department|name|salary|\n",
       "+----------+----+------+\n",
       "|        IT|John| 60000|\n",
       "|        IT|Mike| 70000|\n",
       "|        IT| Tom| 65000|\n",
       "|        IT|Mark| 68000|\n",
       "|        IT|John| 60000|\n",
       "+----------+----+------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select department,name,salary from DF where department=='IT'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20490e82",
   "metadata": {},
   "source": [
    "# Filtering Data\n",
    "2.Write a PySpark code to filter out employees who joined after \"2021-01-01\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "820c6bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.join_date > '2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "040eb811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.join_date > '2022-07-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aceba8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from DF where join_date > '2022-07-14'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae5cfe",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "3.Write a PySpark code to calculate the average salary of employees in each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5db64e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>round(avg(salary), 2)</th></tr>\n",
       "<tr><td>IT</td><td>64600.0</td></tr>\n",
       "<tr><td>HR</td><td>57333.33</td></tr>\n",
       "<tr><td>Finance</td><td>73500.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------------------+\n",
       "|department|round(avg(salary), 2)|\n",
       "+----------+---------------------+\n",
       "|        IT|              64600.0|\n",
       "|        HR|             57333.33|\n",
       "|   Finance|              73500.0|\n",
       "+----------+---------------------+"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"department\").agg(round(avg(\"salary\"), 2)).alias(\"avg_salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "394ed04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>round(avg(salary), 2)</th></tr>\n",
       "<tr><td>IT</td><td>64600.0</td></tr>\n",
       "<tr><td>HR</td><td>57333.33</td></tr>\n",
       "<tr><td>Finance</td><td>73500.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------------------+\n",
       "|department|round(avg(salary), 2)|\n",
       "+----------+---------------------+\n",
       "|        IT|              64600.0|\n",
       "|        HR|             57333.33|\n",
       "|   Finance|              73500.0|\n",
       "+----------+---------------------+"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select department,round(avg(salary),2) from DF group by department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19894f1",
   "metadata": {},
   "source": [
    "# Sorting\n",
    "4.Write a PySpark code to sort the DataFrame by salary in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "306af775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort('salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f88edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a67618f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from DF order by salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d0381",
   "metadata": {},
   "source": [
    "# Column Operations\n",
    "5.Write a PySpark code to add a new column named salary_increase which is 10% of the current salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88970ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>salary_increase</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>6000.0</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>5500.0</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>7000.0</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>7500.0</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>5800.0</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>6500.0</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>7200.0</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>6800.0</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>5900.0</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>6000.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+---------------+\n",
       "|emp_id|name|department|salary| join_date|salary_increase|\n",
       "+------+----+----------+------+----------+---------------+\n",
       "|     1|John|        IT| 60000|2022-01-15|         6000.0|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|         5500.0|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|         7000.0|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|         7500.0|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|         5800.0|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|         6500.0|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|         7200.0|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|         6800.0|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|         5900.0|\n",
       "|    10|John|        IT| 60000|2022-01-15|         6000.0|\n",
       "+------+----+----------+------+----------+---------------+"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"salary_increase\",col(\"salary\")*0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37d1bdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>salary_increase</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>6000.00</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>5500.00</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>7000.00</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>7500.00</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>5800.00</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>6500.00</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>7200.00</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>6800.00</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>5900.00</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>6000.00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+---------------+\n",
       "|emp_id|name|department|salary| join_date|salary_increase|\n",
       "+------+----+----------+------+----------+---------------+\n",
       "|     1|John|        IT| 60000|2022-01-15|        6000.00|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|        5500.00|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|        7000.00|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|        7500.00|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|        5800.00|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|        6500.00|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|        7200.00|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|        6800.00|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|        5900.00|\n",
       "|    10|John|        IT| 60000|2022-01-15|        6000.00|\n",
       "+------+----+----------+------+----------+---------------+"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"salary_increase\", expr(\"salary * 0.10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "723c28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+----------+----------+\n",
      "|emp_id|name|department|salary| join_date|new_salary|\n",
      "+------+----+----------+------+----------+----------+\n",
      "|     1|John|        IT| 60000|2022-01-15|  66000.00|\n",
      "|     2|Jane|        HR| 55000|2021-03-22|  60500.00|\n",
      "|     3|Mike|        IT| 70000|2022-06-18|  77000.00|\n",
      "|     4|Sara|   Finance| 75000|2020-11-30|  82500.00|\n",
      "|     5| Amy|        HR| 58000|2021-05-10|  63800.00|\n",
      "|     6| Tom|        IT| 65000|2023-02-25|  71500.00|\n",
      "|     7|Lisa|   Finance| 72000|2022-07-14|  79200.00|\n",
      "|     8|Mark|        IT| 68000|2021-12-01|  74800.00|\n",
      "|     9| Eva|        HR| 59000|2020-09-10|  64900.00|\n",
      "|    10|John|        IT| 60000|2022-01-15|  66000.00|\n",
      "+------+----+----------+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating new column new salary after adding 10% increment\n",
    "df.withColumn(\"new_salary\",expr(\"(salary*0.10)+salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09a7ec",
   "metadata": {},
   "source": [
    "# Date Manipulation\n",
    "6.Write a PySpark code to extract the year from the join_date column and create a new column join_year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82eef351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>year</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>2022</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>2021</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>2022</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>2020</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>2021</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>2023</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>2022</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>2021</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>2020</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>2022</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+----+\n",
       "|emp_id|name|department|salary| join_date|year|\n",
       "+------+----+----------+------+----------+----+\n",
       "|     1|John|        IT| 60000|2022-01-15|2022|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|2021|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|2022|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|2020|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|2021|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|2023|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|2022|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|2021|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|2020|\n",
       "|    10|John|        IT| 60000|2022-01-15|2022|\n",
       "+------+----+----------+------+----------+----+"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"year\",year(\"join_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6f115e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>month</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>1</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>3</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>6</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>11</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>5</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>2</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>7</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>12</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>9</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+-----+\n",
       "|emp_id|name|department|salary| join_date|month|\n",
       "+------+----+----------+------+----------+-----+\n",
       "|     1|John|        IT| 60000|2022-01-15|    1|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|    3|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|    6|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|   11|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|    5|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|    2|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|    7|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|   12|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|    9|\n",
       "|    10|John|        IT| 60000|2022-01-15|    1|\n",
       "+------+----+----------+------+----------+-----+"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"month\",month(\"join_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfe1ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>day</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>15</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>22</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>18</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>30</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>10</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>25</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>14</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>1</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>10</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>15</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+---+\n",
       "|emp_id|name|department|salary| join_date|day|\n",
       "+------+----+----------+------+----------+---+\n",
       "|     1|John|        IT| 60000|2022-01-15| 15|\n",
       "|     2|Jane|        HR| 55000|2021-03-22| 22|\n",
       "|     3|Mike|        IT| 70000|2022-06-18| 18|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30| 30|\n",
       "|     5| Amy|        HR| 58000|2021-05-10| 10|\n",
       "|     6| Tom|        IT| 65000|2023-02-25| 25|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14| 14|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|  1|\n",
       "|     9| Eva|        HR| 59000|2020-09-10| 10|\n",
       "|    10|John|        IT| 60000|2022-01-15| 15|\n",
       "+------+----+----------+------+----------+---+"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"day\",dayofmonth(\"join_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ede10d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+----------+----+\n",
      "|emp_id|name|department|salary| join_date|year|\n",
      "+------+----+----------+------+----------+----+\n",
      "|     1|John|        IT| 60000|2022-01-15|2022|\n",
      "|     2|Jane|        HR| 55000|2021-03-22|2021|\n",
      "|     3|Mike|        IT| 70000|2022-06-18|2022|\n",
      "|     4|Sara|   Finance| 75000|2020-11-30|2020|\n",
      "|     5| Amy|        HR| 58000|2021-05-10|2021|\n",
      "|     6| Tom|        IT| 65000|2023-02-25|2023|\n",
      "|     7|Lisa|   Finance| 72000|2022-07-14|2022|\n",
      "|     8|Mark|        IT| 68000|2021-12-01|2021|\n",
      "|     9| Eva|        HR| 59000|2020-09-10|2020|\n",
      "|    10|John|        IT| 60000|2022-01-15|2022|\n",
      "+------+----+----------+------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select *,year(join_date) as year from DF\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4891cd2a",
   "metadata": {},
   "source": [
    "# Group By and Aggregation\n",
    "7.Write a PySpark code to group employees by department and count the number of employees in each department.# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29c832fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>count(name)</th></tr>\n",
       "<tr><td>IT</td><td>5</td></tr>\n",
       "<tr><td>HR</td><td>3</td></tr>\n",
       "<tr><td>Finance</td><td>2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-----------+\n",
       "|department|count(name)|\n",
       "+----------+-----------+\n",
       "|        IT|          5|\n",
       "|        HR|          3|\n",
       "|   Finance|          2|\n",
       "+----------+-----------+"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('department').agg(count('name')).alias(\"no_of_employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf91da5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>no_of_employees</th></tr>\n",
       "<tr><td>IT</td><td>5</td></tr>\n",
       "<tr><td>HR</td><td>3</td></tr>\n",
       "<tr><td>Finance</td><td>2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+---------------+\n",
       "|department|no_of_employees|\n",
       "+----------+---------------+\n",
       "|        IT|              5|\n",
       "|        HR|              3|\n",
       "|   Finance|              2|\n",
       "+----------+---------------+"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select department,count(name) as no_of_employees from DF group by department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26269f",
   "metadata": {},
   "source": [
    "# String Operations\n",
    "8.Write a PySpark code to create a new column full_name that concatenates name with the department, separated by a hyphen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af9384aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>full_name</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>John - IT</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>Jane - HR</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>Mike - IT</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>Sara - Finance</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>Amy - HR</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>Tom - IT</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>Lisa - Finance</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>Mark - IT</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>Eva - HR</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>John - IT</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+--------------+\n",
       "|emp_id|name|department|salary| join_date|     full_name|\n",
       "+------+----+----------+------+----------+--------------+\n",
       "|     1|John|        IT| 60000|2022-01-15|     John - IT|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|     Jane - HR|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|     Mike - IT|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|Sara - Finance|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|      Amy - HR|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|      Tom - IT|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|Lisa - Finance|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|     Mark - IT|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|      Eva - HR|\n",
       "|    10|John|        IT| 60000|2022-01-15|     John - IT|\n",
       "+------+----+----------+------+----------+--------------+"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lit(\" - \") creates a literal value for the hyphen and space between the name and department columns.\n",
    "df.withColumn(\"full_name\",concat('name',lit(\" - \"),'department'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "657c4afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>full_name</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>John - IT</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>Jane - HR</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>Mike - IT</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>Sara - Finance</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>Amy - HR</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>Tom - IT</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>Lisa - Finance</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>Mark - IT</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>Eva - HR</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>John - IT</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+--------------+\n",
       "|emp_id|name|department|salary| join_date|     full_name|\n",
       "+------+----+----------+------+----------+--------------+\n",
       "|     1|John|        IT| 60000|2022-01-15|     John - IT|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|     Jane - HR|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|     Mike - IT|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|Sara - Finance|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|      Amy - HR|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|      Tom - IT|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|Lisa - Finance|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|     Mark - IT|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|      Eva - HR|\n",
       "|    10|John|        IT| 60000|2022-01-15|     John - IT|\n",
       "+------+----+----------+------+----------+--------------+"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select *,concat(name,' - ',department) as full_name \\\n",
    "          from DF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12d288",
   "metadata": {},
   "source": [
    "# Duplicate Rows\n",
    "9.Write a PySpark code to drop duplicate rows based on the emp_id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "87942f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no duplicates in emp_id\n",
    "df.drop_duplicates([\"emp_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "617d02ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one duplicate in name so removed and remaining data is printed\n",
    "df.dropDuplicates([\"name\"]).orderBy(\"emp_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "81a69f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\" WITH ranked_employees AS (\\\n",
    "        SELECT *,\\\n",
    "               ROW_NUMBER() OVER (PARTITION BY name ORDER BY emp_id) AS rn\\\n",
    "        FROM DF\\\n",
    "    )\\\n",
    "    SELECT emp_id, name, department, salary, join_date\\\n",
    "    FROM ranked_employees\\\n",
    "    WHERE rn = 1 order by emp_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb590a",
   "metadata": {},
   "source": [
    "# Joining DataFrames\n",
    "10.Write a PySpark code to join this DataFrame with another DataFrame df2 on the emp_id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb68512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [\n",
    "    (1, \"Manager\"),\n",
    "    (2, \"Specialist\"),\n",
    "    (3, \"Developer\"),\n",
    "    (4, \"Analyst\"),\n",
    "    (5, \"Consultant\"),\n",
    "    (6, \"Lead\"),\n",
    "    (7, \"Associate\"),\n",
    "    (8, \"Manager\"),\n",
    "    (9, \"Executive\"),\n",
    "    (10, \"Manager\")\n",
    "]\n",
    "\n",
    "# Create DataFrame df2\n",
    "columns2 = [\"emp_id\", \"position\"]\n",
    "df2 = spark.createDataFrame(data2, columns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "045ff0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"DF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5faf0f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>position</th></tr>\n",
       "<tr><td>1</td><td>Manager</td></tr>\n",
       "<tr><td>2</td><td>Specialist</td></tr>\n",
       "<tr><td>3</td><td>Developer</td></tr>\n",
       "<tr><td>4</td><td>Analyst</td></tr>\n",
       "<tr><td>5</td><td>Consultant</td></tr>\n",
       "<tr><td>6</td><td>Lead</td></tr>\n",
       "<tr><td>7</td><td>Associate</td></tr>\n",
       "<tr><td>8</td><td>Manager</td></tr>\n",
       "<tr><td>9</td><td>Executive</td></tr>\n",
       "<tr><td>10</td><td>Manager</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----------+\n",
       "|emp_id|  position|\n",
       "+------+----------+\n",
       "|     1|   Manager|\n",
       "|     2|Specialist|\n",
       "|     3| Developer|\n",
       "|     4|   Analyst|\n",
       "|     5|Consultant|\n",
       "|     6|      Lead|\n",
       "|     7| Associate|\n",
       "|     8|   Manager|\n",
       "|     9| Executive|\n",
       "|    10|   Manager|\n",
       "+------+----------+"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b8ae5b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>position</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>Manager</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>Specialist</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>Developer</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>Analyst</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>Consultant</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>Lead</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>Associate</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>Manager</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>Executive</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>Manager</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+----------+\n",
       "|emp_id|name|department|salary| join_date|  position|\n",
       "+------+----+----------+------+----------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|   Manager|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|Specialist|\n",
       "|     3|Mike|        IT| 70000|2022-06-18| Developer|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|   Analyst|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|Consultant|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|      Lead|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14| Associate|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|   Manager|\n",
       "|     9| Eva|        HR| 59000|2020-09-10| Executive|\n",
       "|    10|John|        IT| 60000|2022-01-15|   Manager|\n",
       "+------+----+----------+------+----------+----------+"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.join(df2,on='emp_id',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9bab8142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>position</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>Manager</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>Specialist</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>Developer</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>Consultant</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>Analyst</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>Lead</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>Associate</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>Manager</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>Executive</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>Manager</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+----------+\n",
       "|emp_id|name|department|salary| join_date|  position|\n",
       "+------+----+----------+------+----------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|   Manager|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|Specialist|\n",
       "|     3|Mike|        IT| 70000|2022-06-18| Developer|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|Consultant|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|   Analyst|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|      Lead|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14| Associate|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|   Manager|\n",
       "|     9| Eva|        HR| 59000|2020-09-10| Executive|\n",
       "|    10|John|        IT| 60000|2022-01-15|   Manager|\n",
       "+------+----+----------+------+----------+----------+"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"select DF.emp_id,  \n",
    "        DF.name, \n",
    "        DF.department, \n",
    "        DF.salary, \n",
    "        DF.join_date,\n",
    "        DF2.position from DF left join DF2 on DF.emp_id==DF2.emp_id\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "885be557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>emp_id</th><th>position</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>1</td><td>Manager</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>2</td><td>Specialist</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>3</td><td>Developer</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>5</td><td>Consultant</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>4</td><td>Analyst</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>6</td><td>Lead</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>7</td><td>Associate</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>8</td><td>Manager</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>9</td><td>Executive</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>10</td><td>Manager</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|emp_id|  position|\n",
       "+------+----+----------+------+----------+------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|     1|   Manager|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|     2|Specialist|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|     3| Developer|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|     5|Consultant|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|     4|   Analyst|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|     6|      Lead|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|     7| Associate|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|     8|   Manager|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|     9| Executive|\n",
       "|    10|John|        IT| 60000|2022-01-15|    10|   Manager|\n",
       "+------+----+----------+------+----------+------+----------+"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from DF left join DF2 on DF.emp_id==DF2.emp_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed01c071",
   "metadata": {},
   "source": [
    "# Handling Null Values\n",
    "11.Write a PySpark code to fill null values in the salary column with the average salary of the department.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7891ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_salary_by_dept = df.groupBy(\"department\").agg(avg(\"salary\").alias(\"avg_salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2281ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_avg = df.join(avg_salary_by_dept, on=\"department\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7dc3d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df_with_avg.withColumn(\n",
    "    \"salary\",\n",
    "    coalesce(col(\"salary\"), col(\"avg_salary\"))\n",
    ").drop(\"avg_salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "975a16bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>emp_id</th><th>name</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>IT</td><td>1</td><td>John</td><td>60000.0</td><td>2022-01-15</td></tr>\n",
       "<tr><td>HR</td><td>2</td><td>Jane</td><td>55000.0</td><td>2021-03-22</td></tr>\n",
       "<tr><td>IT</td><td>3</td><td>Mike</td><td>70000.0</td><td>2022-06-18</td></tr>\n",
       "<tr><td>HR</td><td>5</td><td>Amy</td><td>58000.0</td><td>2021-05-10</td></tr>\n",
       "<tr><td>Finance</td><td>4</td><td>Sara</td><td>75000.0</td><td>2020-11-30</td></tr>\n",
       "<tr><td>IT</td><td>6</td><td>Tom</td><td>65000.0</td><td>2023-02-25</td></tr>\n",
       "<tr><td>Finance</td><td>7</td><td>Lisa</td><td>72000.0</td><td>2022-07-14</td></tr>\n",
       "<tr><td>IT</td><td>8</td><td>Mark</td><td>68000.0</td><td>2021-12-01</td></tr>\n",
       "<tr><td>HR</td><td>9</td><td>Eva</td><td>59000.0</td><td>2020-09-10</td></tr>\n",
       "<tr><td>IT</td><td>10</td><td>John</td><td>60000.0</td><td>2022-01-15</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+------+----+-------+----------+\n",
       "|department|emp_id|name| salary| join_date|\n",
       "+----------+------+----+-------+----------+\n",
       "|        IT|     1|John|60000.0|2022-01-15|\n",
       "|        HR|     2|Jane|55000.0|2021-03-22|\n",
       "|        IT|     3|Mike|70000.0|2022-06-18|\n",
       "|        HR|     5| Amy|58000.0|2021-05-10|\n",
       "|   Finance|     4|Sara|75000.0|2020-11-30|\n",
       "|        IT|     6| Tom|65000.0|2023-02-25|\n",
       "|   Finance|     7|Lisa|72000.0|2022-07-14|\n",
       "|        IT|     8|Mark|68000.0|2021-12-01|\n",
       "|        HR|     9| Eva|59000.0|2020-09-10|\n",
       "|        IT|    10|John|60000.0|2022-01-15|\n",
       "+----------+------+----+-------+----------+"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2405d",
   "metadata": {},
   "source": [
    "# Filtering with Conditions\n",
    "12.Write a PySpark code to filter employees who either have a salary greater than 65000 or have joined in 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2863f20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((col('salary') > 65000) | (year(col('join_date')) == 2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c171dc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+\n",
       "|emp_id|name|department|salary| join_date|\n",
       "+------+----+----------+------+----------+\n",
       "|     1|John|        IT| 60000|2022-01-15|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|\n",
       "|    10|John|        IT| 60000|2022-01-15|\n",
       "+------+----+----------+------+----------+"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from DF where salary > 65000 or year(join_date)=2022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82d90f",
   "metadata": {},
   "source": [
    "# Window Functions\n",
    "13.Write a PySpark code to add a column rank which ranks employees within each department based on their salary in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ad221e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "#Define the window specification\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f78583c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>row_number</th></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>1</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>2</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>1</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>2</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>3</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>1</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>2</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>3</td></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>4</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>5</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+----------+\n",
       "|emp_id|name|department|salary| join_date|row_number|\n",
       "+------+----+----------+------+----------+----------+\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|         1|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|         2|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|         1|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|         2|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|         3|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|         1|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|         2|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|         3|\n",
       "|     1|John|        IT| 60000|2022-01-15|         4|\n",
       "|    10|John|        IT| 60000|2022-01-15|         5|\n",
       "+------+----+----------+------+----------+----------+"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"row_number\", row_number().over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "270d9a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>rank</th></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>1</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>2</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>1</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>2</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>3</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>1</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>2</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>3</td></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>4</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>4</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+----+\n",
       "|emp_id|name|department|salary| join_date|rank|\n",
       "+------+----+----------+------+----------+----+\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|   1|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|   2|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|   1|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|   2|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|   3|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|   1|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|   2|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|   3|\n",
       "|     1|John|        IT| 60000|2022-01-15|   4|\n",
       "|    10|John|        IT| 60000|2022-01-15|   4|\n",
       "+------+----+----------+------+----------+----+"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"rank\", rank().over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "69cc1757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>rn</th></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>1</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>2</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>1</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>2</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>3</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>1</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>2</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>3</td></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>4</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>4</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+---+\n",
       "|emp_id|name|department|salary| join_date| rn|\n",
       "+------+----+----------+------+----------+---+\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|  1|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|  2|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|  1|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|  2|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|  3|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|  1|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|  2|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|  3|\n",
       "|     1|John|        IT| 60000|2022-01-15|  4|\n",
       "|    10|John|        IT| 60000|2022-01-15|  4|\n",
       "+------+----+----------+------+----------+---+"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "select *,\n",
    "rank() over(partition by department order by salary desc) as rn\n",
    "from DF\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfc138",
   "metadata": {},
   "source": [
    "# Pivot Tables\n",
    "14.Write a PySpark code to pivot the DataFrame to show the sum of salaries for each department by year of join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "59349c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the join_date column\n",
    "df_with_year = df.withColumn(\"join_year\", year(col(\"join_date\")))\n",
    "\n",
    "# Pivot the DataFrame to show the sum of salaries for each department by year of join\n",
    "pivot_df = df_with_year.groupBy(\"department\").pivot(\"join_year\").agg(sum(\"salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "41cee7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>emp_id</th><th>name</th><th>department</th><th>salary</th><th>join_date</th><th>join_year</th></tr>\n",
       "<tr><td>1</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>2022</td></tr>\n",
       "<tr><td>2</td><td>Jane</td><td>HR</td><td>55000</td><td>2021-03-22</td><td>2021</td></tr>\n",
       "<tr><td>3</td><td>Mike</td><td>IT</td><td>70000</td><td>2022-06-18</td><td>2022</td></tr>\n",
       "<tr><td>4</td><td>Sara</td><td>Finance</td><td>75000</td><td>2020-11-30</td><td>2020</td></tr>\n",
       "<tr><td>5</td><td>Amy</td><td>HR</td><td>58000</td><td>2021-05-10</td><td>2021</td></tr>\n",
       "<tr><td>6</td><td>Tom</td><td>IT</td><td>65000</td><td>2023-02-25</td><td>2023</td></tr>\n",
       "<tr><td>7</td><td>Lisa</td><td>Finance</td><td>72000</td><td>2022-07-14</td><td>2022</td></tr>\n",
       "<tr><td>8</td><td>Mark</td><td>IT</td><td>68000</td><td>2021-12-01</td><td>2021</td></tr>\n",
       "<tr><td>9</td><td>Eva</td><td>HR</td><td>59000</td><td>2020-09-10</td><td>2020</td></tr>\n",
       "<tr><td>10</td><td>John</td><td>IT</td><td>60000</td><td>2022-01-15</td><td>2022</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+----+----------+------+----------+---------+\n",
       "|emp_id|name|department|salary| join_date|join_year|\n",
       "+------+----+----------+------+----------+---------+\n",
       "|     1|John|        IT| 60000|2022-01-15|     2022|\n",
       "|     2|Jane|        HR| 55000|2021-03-22|     2021|\n",
       "|     3|Mike|        IT| 70000|2022-06-18|     2022|\n",
       "|     4|Sara|   Finance| 75000|2020-11-30|     2020|\n",
       "|     5| Amy|        HR| 58000|2021-05-10|     2021|\n",
       "|     6| Tom|        IT| 65000|2023-02-25|     2023|\n",
       "|     7|Lisa|   Finance| 72000|2022-07-14|     2022|\n",
       "|     8|Mark|        IT| 68000|2021-12-01|     2021|\n",
       "|     9| Eva|        HR| 59000|2020-09-10|     2020|\n",
       "|    10|John|        IT| 60000|2022-01-15|     2022|\n",
       "+------+----+----------+------+----------+---------+"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c24f4a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>department</th><th>2020</th><th>2021</th><th>2022</th><th>2023</th></tr>\n",
       "<tr><td>HR</td><td>59000</td><td>113000</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>Finance</td><td>75000</td><td>null</td><td>72000</td><td>null</td></tr>\n",
       "<tr><td>IT</td><td>null</td><td>68000</td><td>190000</td><td>65000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "DataFrame[department: string, 2020: bigint, 2021: bigint, 2022: bigint, 2023: bigint]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The pivot function rearranges data,\n",
    "#so that the unique values of a specified column become new column headers,\n",
    "#and the corresponding values in another column are aggregated.\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1f3fb",
   "metadata": {},
   "source": [
    "# Complex Aggregation\n",
    "15.Write a PySpark code to calculate the maximum salary for each department and the percentage difference from the average salary in that department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e059fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "avg_salary=df.groupBy('department').agg(avg('salary').cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fa40e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_salary=df.groupBy('department').agg(max('salary').cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "91450718",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df=avg_salary.join(max_salary,on='department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4d434e89",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `max_salary` cannot be resolved. Did you mean one of the following? [`department`, `CAST(max(salary) AS DOUBLE)`, `CAST(avg(salary) AS DOUBLE)`].;\n'Project [department#530, CAST(avg(salary) AS DOUBLE)#5460, CAST(max(salary) AS DOUBLE)#5469, ((('max_salary - 'avg_salary) / 'avg_salary) * 100) AS percentage_difference#5480]\n+- Project [department#530, CAST(avg(salary) AS DOUBLE)#5460, CAST(max(salary) AS DOUBLE)#5469]\n   +- Join Inner, (department#530 = department#5474)\n      :- Aggregate [department#530], [department#530, cast(avg(salary#531L) as double) AS CAST(avg(salary) AS DOUBLE)#5460]\n      :  +- LogicalRDD [emp_id#528L, name#529, department#530, salary#531L, join_date#532], false\n      +- Aggregate [department#5474], [department#5474, cast(max(salary#5475L) as double) AS CAST(max(salary) AS DOUBLE)#5469]\n         +- LogicalRDD [emp_id#5472L, name#5473, department#5474, salary#5475L, join_date#5476], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m joined_df\u001b[38;5;241m.\u001b[39mwithColumn(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpercentage_difference\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     ((col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_salary\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_salary\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m/\u001b[39m col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_salary\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:4789\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   4784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[0;32m   4785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   4786\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4787\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   4788\u001b[0m     )\n\u001b[1;32m-> 4789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mwithColumn(colName, col\u001b[38;5;241m.\u001b[39m_jc), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `max_salary` cannot be resolved. Did you mean one of the following? [`department`, `CAST(max(salary) AS DOUBLE)`, `CAST(avg(salary) AS DOUBLE)`].;\n'Project [department#530, CAST(avg(salary) AS DOUBLE)#5460, CAST(max(salary) AS DOUBLE)#5469, ((('max_salary - 'avg_salary) / 'avg_salary) * 100) AS percentage_difference#5480]\n+- Project [department#530, CAST(avg(salary) AS DOUBLE)#5460, CAST(max(salary) AS DOUBLE)#5469]\n   +- Join Inner, (department#530 = department#5474)\n      :- Aggregate [department#530], [department#530, cast(avg(salary#531L) as double) AS CAST(avg(salary) AS DOUBLE)#5460]\n      :  +- LogicalRDD [emp_id#528L, name#529, department#530, salary#531L, join_date#532], false\n      +- Aggregate [department#5474], [department#5474, cast(max(salary#5475L) as double) AS CAST(max(salary) AS DOUBLE)#5469]\n         +- LogicalRDD [emp_id#5472L, name#5473, department#5474, salary#5475L, join_date#5476], false\n"
     ]
    }
   ],
   "source": [
    "joined_df.withColumn(\n",
    "    \"percentage_difference\",\n",
    "    ((col(\"max_salary\") - col(\"avg_salary\")) / col(\"avg_salary\")) * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0a50898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf68aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
